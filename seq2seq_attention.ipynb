{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.preprocessing data\n",
    "# 2.build model\n",
    "# 2.1 encoder\n",
    "# 2.2 attention\n",
    "# 2.3 decoder\n",
    "# 2.4 loss & optimizer\n",
    "# 2.5 train\n",
    "# 3. evaluation\n",
    "# 3.1 given sentence,return translated results\n",
    "# 3.2 visualize results (attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May I borrow this book?\n",
      "Tomatelo con soda.\n"
     ]
    }
   ],
   "source": [
    "en_spa_file_path = './spa.txt'\n",
    "import unicodedata\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\n",
    "\n",
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"Tomátelo con soda.\"\n",
    "print(unicode_to_ascii(en_sentence))\n",
    "print(unicode_to_ascii(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "<start> tomatelo con soda . <end>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess_sentence(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    # 标点符号前后加空格\n",
    "    s = re.sub(r\"([?.!,¿])\",r\" \\1 \",s)\n",
    "    # 多余空格变一个空格 \n",
    "    s = re.sub(r'[\" \"]+',\" \",s)\n",
    "    # 除了标点符号和字母外都是空格\n",
    "    s = re.sub(r'[^a-zA-Z?.!,¿]',' ',s)\n",
    "    # 去掉前后空格\n",
    "    s = s.rstrip().strip()\n",
    "    s = '<start> '+s+ ' <end>'\n",
    "    return s\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "def perse_data(filename):\n",
    "    lines = open(filename,encoding='UTF-8').read().strip().split('\\n')\n",
    "    sentence_pairs = [line.split('\\t') for line in lines ]\n",
    "    preprocessed_sentence_pairs = [\n",
    "        (preprocess_sentence(en),preprocess_sentence(sp)) for en,sp in sentence_pairs ]\n",
    "    return zip(*preprocessed_sentence_pairs)\n",
    "en_dataset,sp_dataset =  perse_data(en_spa_file_path)\n",
    "print(en_dataset[-1])\n",
    "print(sp_dataset[-1])\n",
    "print(type(en_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 5) (2, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "a = [(1,2),(3,4),(5,6)]\n",
    "c, d = zip(*a)\n",
    "print(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 16)\n",
      "(30000, 11)\n",
      "16 11\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(lang):\n",
    "    lang_tokenizer = keras.preprocessing.text.Tokenizer(num_words=None,filters='',split=' ')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    # maxlen=None 默认序列的最大长度\n",
    "    tensor = keras.preprocessing.sequence.pad_sequences(tensor,padding = 'post')\n",
    "    return tensor ,lang_tokenizer\n",
    "input_tensor,input_tokenizer = tokenizer(sp_dataset[0:30000])\n",
    "output_tensor,output_tokenizer = tokenizer(en_dataset[0:30000])\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "max_length_input = max_length(input_tensor)\n",
    "max_length_output = max_length(output_tensor)\n",
    "print(input_tensor.shape)\n",
    "print(output_tensor.shape)\n",
    "print(max_length_input,max_length_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 6000, 24000, 6000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "input_train,input_eval,output_train,output_eval = train_test_split(input_tensor,output_tensor,test_size = 0.2)\n",
    "len(input_train),len(input_eval),len(output_train),len(output_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --><start>\n",
      "12 -->me\n",
      "40 -->gusta\n",
      "163 -->ver\n",
      "13 -->la\n",
      "248 -->television\n",
      "3 -->.\n",
      "2 --><end>\n",
      "\n",
      "1 --><start>\n",
      "4 -->i\n",
      "35 -->like\n",
      "408 -->watching\n",
      "215 -->tv\n",
      "3 -->.\n",
      "2 --><end>\n"
     ]
    }
   ],
   "source": [
    "def convert(example,tokenizer):\n",
    "    for t in example:\n",
    "        if t != 0:\n",
    "            print('%d -->%s'%(t,tokenizer.index_word[t]))\n",
    "convert(input_train[0],input_tokenizer)\n",
    "print()\n",
    "convert(output_train[0],output_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(input_tensor,output_tensor,batch_size,epochs,shuffle):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor,output_tensor))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(30000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size,drop_remainder = True)\n",
    "    return dataset\n",
    "batch_size =64\n",
    "epochs =20\n",
    "train_dataset = make_dataset(input_train,output_train,batch_size,epochs,True)\n",
    "eval_dataset = make_dataset(input_eval,output_eval,batch_size,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_units = 256\n",
    "units = 1024\n",
    "# 字典长度加1  为补齐的0向量\n",
    "input_vocab_size = len(input_tokenizer.word_index)+1\n",
    "output_vocab_size = len(output_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n",
      "(64, 11)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_output.shape: (64, 16, 1024)\n",
      "sample_hidden.shape: (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_units,encoding_units,batch_size):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size,embedding_units)\n",
    "        self.gru = keras.layers.GRU(self.encoding_units,\n",
    "                                    return_sequences = True,\n",
    "                                    return_state = True,\n",
    "                                    recurrent_initializer = 'glorot_uniform')\n",
    "    def call(self,x,hidden):\n",
    "        x = self.embedding(x)\n",
    "        output,state = self.gru(x,initial_state = hidden)\n",
    "        return output,state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size,self.encoding_units))\n",
    "encoder = Encoder(input_vocab_size,embedding_units,units,batch_size)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "# return_sequence返回每个时间步上的隐状态（hidden state），return_state返回最后一个时间步上细胞状态（cell state）\n",
    "sample_output,sample_hidden = encoder(x,sample_hidden)\n",
    "print(\"sample_output.shape:\",sample_output.shape)\n",
    "print(\"sample_hidden.shape:\",sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_results.shape: (64, 1024)\n",
      "attention_weights.shape: (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(keras.Model):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.W1 = keras.layers.Dense(units)\n",
    "        self.W2 = keras.layers.Dense(units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "    def call(self,decoder_hidden,encoder_outputs):\n",
    "        # decoder_hidden.shape: (bath_size,units)\n",
    "        # encoder_outputs.shape: (batch_size,length,units)\n",
    "        # 维度扩展 ecoder_hidden.shape: (bath_size,1，units)\n",
    "        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden,1)\n",
    "        # before V: (batch_size,length.units)\n",
    "        # ather V: (batch_size,length,1)\n",
    "        # print(self.W1(encoder_outputs).shape)  (64, 16, 10)\n",
    "        # print(self.W2(decoder_hidden_with_time_axis).shape)   (64, 1, 10)\n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n",
    "        # print(score.shape) (64, 16, 1)\n",
    "        # shape: (batch_size,length,1)\n",
    "        attention_weights = tf.nn.softmax(score,axis = 1)\n",
    "        # context_vector (batch_size,length,units)\n",
    "        context_vector = attention_weights * encoder_outputs\n",
    "        # context_vector.shape: (batch_size,units)\n",
    "        context_vector = tf.reduce_sum(context_vector,axis =1 )\n",
    "        return context_vector,attention_weights\n",
    "# 测试\n",
    "attention_model = BahdanauAttention(units = 10)\n",
    "attention_results,attention_weights = attention_model(sample_hidden,sample_output)\n",
    "print(\"attention_results.shape:\",attention_results.shape)\n",
    "print(\"attention_weights.shape:\",attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output.shape: (64, 4935)\n",
      "decoder_hidden.shape: (64, 1024)\n",
      "decoder_aw.shape (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim,decoding_units,batch_size):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size,embedding_units)\n",
    "        self.gru = keras.layers.GRU(self.decoding_units,\n",
    "                                    return_sequences= True,\n",
    "                                    return_state = True,\n",
    "                                    recurrent_initializer = 'glorot_uniform')\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.decoding_units)\n",
    "    def call(self,x,hidden,encoding_outputs):\n",
    "        # context_vector.shape: (batch_size,units)\n",
    "        context_vector,attention_weights = self.attention(hidden,encoding_outputs)\n",
    "        # x 为单词\n",
    "        # before embedding : x.shape: (batch_size,1)\n",
    "        # after embedding : x.shape: (batch_size,1,embedding_units)\n",
    "        x = self.embedding(x)\n",
    "        combined_x = tf.concat([tf.expand_dims(context_vector,1),x],axis=-1)\n",
    "        # print(combined_x.shape)  (64, 1, 1280)  1024+256\n",
    "        # output.shape: [batch_size,1,decoding_units]\n",
    "        # state.shape : [batch_size,decoding_units]\n",
    "        output,state = self.gru(combined_x)\n",
    "        # output.shape: [batch_size,decoding_units]\n",
    "        output = tf.reshape(output,(-1,output.shape[2]))\n",
    "        # output.shape: [batch_size,vocab_size]\n",
    "        output = self.fc(output)\n",
    "        return output,state,attention_weights\n",
    "\n",
    "decoder = Decoder(output_vocab_size,embedding_units,units,batch_size)\n",
    "outputs = decoder(tf.random.uniform((batch_size,1)),sample_hidden,sample_output)\n",
    "decoder_output,decoder_hidden,decoder_aw = outputs\n",
    "print(\"decoder_output.shape:\",decoder_output.shape)\n",
    "print(\"decoder_hidden.shape:\",decoder_hidden.shape)\n",
    "print(\"decoder_aw.shape\",decoder_aw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
    "\n",
    "def loss_function(real,pred):\n",
    "    # targ很多padding为0的部分 将这些部分不加入损失函数计算\n",
    "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
    "    # 计算出每个targ对应的损失\n",
    "    loss_ = loss_object(real,pred)\n",
    "    mask = tf.cast(mask,dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    print(loss_)\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.6897267], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_true = [1]\n",
    "y_pred = [[0.1, 0.8, 0.1]]\n",
    "loss_v = loss_object(y_true,y_pred)\n",
    "print(loss_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.6897267], shape=(1,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6897267>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp,targ,encoding_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoding_outputs, encoding_hidden = encoder(inp,encoding_hidden)\n",
    "        decoding_hidden = encoding_hidden \n",
    "        # eg: <start> I am here <end>\n",
    "        # 1. <start> -> I\n",
    "        # 2. I -> am\n",
    "        # 3. am -> here\n",
    "        # 4. here -> <end>\n",
    "        for t in range(0,targ.shape[1]-1):\n",
    "            decoding_input = tf.expand_dims(targ[:,t],1)\n",
    "            predictions,decoding_hidden, _ = decoder(decoding_input,decoding_hidden,encoding_outputs)\n",
    "            loss += loss_function(targ[:,t+1],predictions)\n",
    "    # 计算平均的损失函数\n",
    "    batch_loss = loss /int(targ.shape[0])\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss,variables)\n",
    "    optimizer.apply_gradients(zip(gradients,variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_1:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_2:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_3:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_4:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_5:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_6:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_7:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_8:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_9:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_1:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_2:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_3:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_4:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_5:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_6:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_7:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_8:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"mul_9:0\", shape=(64,), dtype=float32)\n",
      "Epoch1 Batch0 Loss0.8076\n",
      "Epoch1 Batch100 Loss0.3984\n",
      "Epoch1 Batch200 Loss0.3093\n",
      "Epoch1 Batch300 Loss0.2793\n",
      "Epoch1 Batch400 Loss0.2667\n",
      "Epoch1 Loss0.3287\n",
      "Time take for epoch600.8223218917847 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 1\n",
    "steps_per_epoch = len(input_tensor) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    encoding_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch,(inp,targ)) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp,targ,encoding_hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if batch%100 ==0:\n",
    "            print('Epoch{} Batch{} Loss{:.4f}'.format(epoch+1,batch,batch_loss.numpy()))\n",
    "    print('Epoch{} Loss{:.4f}'.format(epoch+1,total_loss/steps_per_epoch))\n",
    "    print('Time take for epoch{} sec\\n'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "def evaluate(input_sentence):\n",
    "    attention_matrix = np.zeros((max_length_output,max_length_input))\n",
    "    input_sentence = preprocess_sentence(input_sentence)\n",
    "    \n",
    "    inputs = [input_tokenizer.word_index[token] for token in input_sentence.split(' ')]\n",
    "    inputs = keras.preprocessing.sequence.pad_sequences([inputs],maxlen = max_length_input,padding= 'post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    results = ''\n",
    "    # encoding_hidden = encoder.initialize_hidden_state()\n",
    "    encoding_hidden = tf.zeros((1,units))\n",
    "    encoding_outputs ,encoding_hidden = encoder(inputs,encoding_hidden)\n",
    "    decoding_hidden = encoding_hidden\n",
    "    \n",
    "    # eg: <start> -> A\n",
    "    # A -> B -> C-> D\n",
    "    \n",
    "    # decoding_input.shape: (1,1)\n",
    "    decoding_input = tf.expand_dims([output_tokenizer.word_index['<start>']],0)\n",
    "    \n",
    "    for t in range(max_length_output):\n",
    "        predictions,decoding_hidden,attention_weights = decoder(decoding_input,decoding_hidden,encoding_outputs)\n",
    "        # attention_weights.shape: (batch_size,input_length,1) (1,16,1)\n",
    "        # 存储注意力权重以便后面制图\n",
    "        attention_weights = tf.reshape(attention_weights,(-1,))\n",
    "        attention_matrix[t] = attention_weights.numpy()\n",
    "        \n",
    "        # predictions.shape:(batch_size,vocab_size)  (1,4935)\n",
    "        print(\"...\",predictions[0])\n",
    "        print(\"re..\",tf.reduce_max(predictions[0]))\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        results += output_tokenizer.index_word[predicted_id]+ ' '\n",
    "        if output_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return results,input_sentence,attention_matrix\n",
    "        # 上一步的输出是下一步的输入\n",
    "        decoding_input = tf.expand_dims([predicted_id],0)\n",
    "    return results,inputs,input_sentence,attention_matrix\n",
    "\n",
    "def plot_attention(attention_matrix,input_sentence,predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.matshow(attention_matrix,cmap='viridis')\n",
    "    \n",
    "    font_dict = {'fontsize':14}\n",
    "    ax.set_xticklabels(['']+input_sentence,fontdict = font_dict,rotation = 90 )\n",
    "    ax.set_yticklabels(['']+predicted_sentence,fontdict = font_dict,)\n",
    "    plt.show()\n",
    "\n",
    "def translate(input_sentence):\n",
    "    results,input_sentence,attention_matrix = evaluate(input_sentence)\n",
    "    print(\"Input:%s\"%(input_sentence))\n",
    "    print(\"Predicted translation:%s\"%(results))\n",
    "    attention_matrix = attention_matrix[:len(results.split(' ')),:len(input_sentence.split(' '))]\n",
    "    plot_attention(attention_matrix,input_sentence.split(' '),results.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... tf.Tensor(\n",
      "[-4.586863   -4.5081024   0.43373042 ... -4.6790557  -4.671134\n",
      " -4.931502  ], shape=(4935,), dtype=float32)\n",
      "re.. tf.Tensor(9.563461, shape=(), dtype=float32)\n",
      "... tf.Tensor([-6.898451  -6.8554425  1.6343931 ... -7.064906  -7.2085648 -7.4278092], shape=(4935,), dtype=float32)\n",
      "re.. tf.Tensor(6.850647, shape=(), dtype=float32)\n",
      "... tf.Tensor([-6.5018945 -6.3931174 -1.7796676 ... -6.6280036 -7.03402   -7.0374756], shape=(4935,), dtype=float32)\n",
      "re.. tf.Tensor(5.5371943, shape=(), dtype=float32)\n",
      "... tf.Tensor([-6.159809  -6.390952   0.2773208 ... -6.6240463 -6.5951724 -6.956583 ], shape=(4935,), dtype=float32)\n",
      "re.. tf.Tensor(8.362355, shape=(), dtype=float32)\n",
      "... tf.Tensor([-4.6508946 -4.809359  17.546335  ... -5.344222  -5.0374603 -4.9174595], shape=(4935,), dtype=float32)\n",
      "re.. tf.Tensor(17.546335, shape=(), dtype=float32)\n",
      "Input:<start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation:is this one ? <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'¿todavia estan en casa?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
